{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "723d3e0a-5315-469b-837b-639d304ee976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import math, random, sys\n",
    "import pickle\n",
    "import argparse\n",
    "from functools import partial\n",
    "import torch\n",
    "import numpy\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "from hgraph import MolGraph, common_atom_vocab, PairVocab\n",
    "import rdkit\n",
    "\n",
    "def to_numpy(tensors):\n",
    "    convert = lambda x : x.numpy() if type(x) is torch.Tensor else x\n",
    "    a,b,c = tensors\n",
    "    b = [convert(x) for x in b[0]], [convert(x) for x in b[1]]\n",
    "    return a, b, c\n",
    "\n",
    "def tensorize(mol_batch, vocab):    \n",
    "#     TypeError\n",
    "    try:\n",
    "        x = MolGraph.tensorize(mol_batch, vocab, common_atom_vocab)\n",
    "        return to_numpy(x)\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def tensorize_pair(mol_batch, vocab):\n",
    "    x, y = zip(*mol_batch)\n",
    "    x = MolGraph.tensorize(x, vocab, common_atom_vocab)\n",
    "    y = MolGraph.tensorize(y, vocab, common_atom_vocab)\n",
    "    return to_numpy(x)[:-1] + to_numpy(y) #no need of order for x\n",
    "\n",
    "def tensorize_cond(mol_batch, vocab):\n",
    "    x, y, cond = zip(*mol_batch)\n",
    "    cond = [map(int, c.split(',')) for c in cond]\n",
    "    cond = numpy.array(cond)\n",
    "    x = MolGraph.tensorize(x, vocab, common_atom_vocab)\n",
    "    y = MolGraph.tensorize(y, vocab, common_atom_vocab)\n",
    "    return to_numpy(x)[:-1] + to_numpy(y) + (cond,) #no need of order for x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2984c8-0648-4214-9bdd-d107bd1b3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARGS:\n",
    "    def __init__(self):\n",
    "        self.train = 'abc'\n",
    "        self.vocab = 'data/chembl/vocab.txt'\n",
    "        self.mode = 'single'\n",
    "        self.ncpu = 8        \n",
    "        self.batch_size = 32\n",
    "\n",
    "args = ARGS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8983991e-afa4-466c-8941-75951de90058",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(args.vocab) as f:\n",
    "    vocab = [x.strip(\"\\r\\n \").split() for x in f]\n",
    "args_vocab = PairVocab(vocab, cuda=False)\n",
    "\n",
    "pool = Pool(args.ncpu) \n",
    "random.seed(1)\n",
    "\n",
    "#dataset contains single molecules\n",
    "with open('/home/quang/working/Theory_of_ML/train_JTNN_full.txt') as f:\n",
    "    data = [line.strip(\"\\r\\n \").split()[0] for line in f]\n",
    "\n",
    "# with open('./data/chembl/all.txt') as f:\n",
    "#     data = [line.strip(\"\\r\\n \").split()[0] for line in f]\n",
    "\n",
    "with open('/home/quang/working/Theory_of_ML/ids_train_JTNN_full.txt') as f:\n",
    "    ids_data = [line.strip(\"\\r\\n \").split()[0] for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ee4d8b-fa71-41ba-9903-3f8915fa5742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664079, 664079)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data), len(ids_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4503f582-56bd-423f-a11e-5bf288de6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, ids_data = shuffle(data, ids_data)\n",
    "data = data[:10_000]\n",
    "ids_data = ids_data[:10_000]\n",
    "#         random.shuffle(data)\n",
    "# data, ids_data = shuffle(data, ids_data)\n",
    "\n",
    "batches = [data[i : i + args.batch_size] for i in range(0, len(data), args.batch_size)]\n",
    "batches_ids = [ids_data[i : i + args.batch_size] for i in range(0, len(ids_data), args.batch_size)]\n",
    "# func = partial(tensorize, vocab = args_vocab)\n",
    "# all_data = pool.map(func, batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03d94d9-58f6-4c20-aa41-2d0c8f60399b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [02:15<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# x = MolGraph.tensorize(data[:20], args_vocab, common_atom_vocab)\n",
    "# len(all_data)\n",
    "# all_data[0]\n",
    "all_data = []\n",
    "all_data_ids = []\n",
    "\n",
    "for b, b_ids in tqdm(zip(batches, batches_ids), total=len(batches)):\n",
    "    t = tensorize(b, args_vocab)\n",
    "    if t is not None:\n",
    "        all_data.append(t)\n",
    "        all_data_ids.append(b_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4ba16bb-a84e-4c8c-92b3-9f2b9eb4488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_splits = len(all_data) // 1000\n",
    "num_splits = len(all_data) // 50\n",
    "\n",
    "le = (len(all_data) + num_splits - 1) // num_splits\n",
    "\n",
    "for split_id in range(num_splits):\n",
    "    st = split_id * le\n",
    "    sub_data = all_data[st : st + le]\n",
    "\n",
    "    with open('./train_processed_bms/mol/tensors-%d.pkl' % split_id, 'wb') as f:\n",
    "        pickle.dump(sub_data, f, pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    sub_data_ids = all_data_ids[st : st + le]\n",
    "\n",
    "    with open('./train_processed_bms/ids/tensors-%d.pkl' % split_id, 'wb') as f:\n",
    "        pickle.dump(sub_data_ids, f, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680a18ba-ed48-44d3-aac6-900d83066fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
